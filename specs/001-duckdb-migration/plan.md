# Implementation Plan: DuckDB Migration

**Branch**: `001-duckdb-migration` | **Date**: 2026-01-31 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-duckdb-migration/spec.md`

## Summary

Migrate the database backend from PostgreSQL to DuckDB to simplify setup and enable better analytics capabilities. The migration replaces the external PostgreSQL server dependency with an embedded DuckDB file while preserving the existing three-stage data pipeline (raw events → parsed events → domain tables). Since the user has opted to start fresh, no data migration is needed—all data will be re-fetched from Tandem Source.

## Technical Context

**Language/Version**: Python 3.12
**Primary Dependencies**: SQLAlchemy 2.x, duckdb-engine, Prefect, loguru
**Storage**: DuckDB (single file at `data/tandem.db`)
**Testing**: pytest (integration tests for pipeline)
**Target Platform**: macOS/Linux desktop
**Project Type**: Single project (CLI tool)
**Performance Goals**: Full historical fetch in reasonable time, efficient analytical queries
**Constraints**: Single-user, single-writer access model (acceptable for use case)
**Scale/Scope**: Years of pump data for one user (~100k-1M events)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

| Principle | Status | Notes |
|-----------|--------|-------|
| I. Data Integrity First | ✅ PASS | Raw events preserved, transactions with rollback, idempotent transforms |
| II. Single-User Simplicity | ✅ PASS | DuckDB simplifies setup significantly - no server needed |
| III. Incremental & Resumable | ✅ PASS | Existing incremental logic preserved |
| IV. Clear Data Pipeline | ✅ PASS | Three-stage pipeline unchanged |
| V. Workflow Orchestration | ✅ PASS | Prefect workflows unchanged |
| Alembic for migrations | ⚠️ ADAPTED | Alembic works with DuckDB via custom impl class |
| Credential Security | ✅ PASS | No changes to credential handling |

**Gate Result**: PASS - All principles satisfied or adapted with justification.

## Project Structure

### Documentation (this feature)

```text
specs/001-duckdb-migration/
├── plan.md              # This file
├── research.md          # DuckDB/SQLAlchemy research findings
├── data-model.md        # Schema documentation
├── quickstart.md        # User guide for new setup
├── contracts/           # CLI interface documentation
│   └── cli-interface.md
└── tasks.md             # Generated by /speckit.tasks
```

### Source Code (repository root)

```text
src/tandem_fetch/
├── __init__.py
├── credentials.py           # No changes
├── definitions.py           # Update DATABASE_URL → DATABASE_PATH
├── tsource.py               # No changes
├── db/
│   ├── __init__.py          # No changes
│   ├── base.py              # No changes
│   ├── raw_events.py        # Add Sequence for auto-increment
│   ├── events.py            # Add Sequence for auto-increment
│   ├── cgm_readings.py      # Add Sequence for auto-increment
│   └── basal_deliveries.py  # Add Sequence for auto-increment
├── pump_events/             # No changes
├── tasks/
│   └── raw_events.py        # Update engine creation
└── workflows/
    ├── get_all_raw_pump_events.py  # Update engine creation
    └── backfills/                   # Update engine creation in each

alembic/
├── alembic.ini              # Update sqlalchemy.url
├── env.py                   # Add AlembicDuckDBImpl class
└── versions/                # Fresh migrations (delete old, create new)

data/                        # New directory (gitignored)
└── tandem.db                # DuckDB database file

pyproject.toml               # Update dependencies
README.md                    # Simplify setup instructions
.gitignore                   # Add data/ directory
```

**Structure Decision**: Single project structure maintained. Key changes are within `db/` models and connection handling. New `data/` directory for DuckDB file.

## Complexity Tracking

No constitution violations requiring justification.

## Implementation Phases

### Phase 1: Dependency Changes

1. Update `pyproject.toml`:
   - Remove: `psycopg2>=2.9.10`
   - Add: `duckdb>=1.0.0`, `duckdb-engine>=0.17.0`

2. Run `uv sync` to update lock file

### Phase 2: Database Configuration

1. Update `src/tandem_fetch/definitions.py`:
   - Replace `DATABASE_URL` with `DATABASE_PATH`
   - Default to `data/tandem.db`
   - Generate DuckDB connection string

2. Create `data/` directory
3. Add `data/` to `.gitignore`

### Phase 3: Model Updates

Update each model file to use Sequences for auto-increment:

1. `db/raw_events.py` - Add `Sequence('raw_events_id_seq')`
2. `db/events.py` - Add `Sequence('events_id_seq')`
3. `db/cgm_readings.py` - Add `Sequence('cgm_readings_id_seq')`
4. `db/basal_deliveries.py` - Add `Sequence('basal_deliveries_id_seq')`

### Phase 4: Alembic Configuration

1. Update `alembic/env.py`:
   - Add `AlembicDuckDBImpl` class
   - Update URL handling for DuckDB

2. Update `alembic.ini`:
   - Set `sqlalchemy.url` to DuckDB path

3. Delete existing migrations in `alembic/versions/`
4. Generate fresh initial migration

### Phase 5: Workflow Updates

Update connection handling in:
1. `workflows/get_all_raw_pump_events.py`
2. `tasks/raw_events.py`
3. `workflows/backfills/0_get_all_raw_pump_events.py`
4. `workflows/backfills/1_parse_events_table.py`
5. `workflows/backfills/2_parse_cgm_readings.py`
6. `workflows/backfills/3_parse_basal_deliveries.py`

### Phase 6: Documentation

1. Update `README.md`:
   - Remove PostgreSQL setup instructions
   - Simplify to single `uv sync` step
   - Update usage examples

### Phase 7: Validation

1. Run `uv sync` to verify dependencies
2. Run `alembic upgrade head` to create schema
3. Run `get-all-raw-pump-events` to verify fetch works
4. Run backfill workflows to verify processing
5. Query data with DuckDB CLI to verify analytics access

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| DuckDB dialect incompatibility | Research confirmed compatibility; fallback to direct DuckDB API if needed |
| Performance regression | DuckDB typically faster for analytics; monitor fetch performance |
| Data loss during migration | Starting fresh - no migration needed; can re-fetch anytime |
| Alembic issues | Keep Alembic simple; can fallback to `create_all()` if problematic |

## Dependencies

```
Phase 1 (Dependencies) → Phase 2 (Config) → Phase 3 (Models) → Phase 4 (Alembic)
                                                                      ↓
                                                              Phase 5 (Workflows)
                                                                      ↓
                                                              Phase 6 (Docs)
                                                                      ↓
                                                              Phase 7 (Validation)
```

## Success Verification

Per spec success criteria:

- [ ] SC-001: `uv sync` is only setup step needed
- [ ] SC-002: All pipeline stages complete with DuckDB
- [ ] SC-003: Full fetch completes without errors
- [ ] SC-004: Analytical queries work in DuckDB CLI
- [ ] SC-005: Database file is portable (copy test)
- [ ] SC-006: README has simplified instructions
